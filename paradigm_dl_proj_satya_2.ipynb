{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12be13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0177a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet.unet import UNet\n",
    "from unet_invoke import train_model, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a859915",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "dataset_dir = \"../dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0bb412",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_a_random_image(dir=dataset_dir + \"/train\"):\n",
    "    all_videos = os.listdir(dir)\n",
    "    picked_video = random.choice(all_videos)\n",
    "    all_images = os.listdir(os.path.join(dir, picked_video))\n",
    "    picked_image = random.choice(all_images)\n",
    "    picked_image_idx = int(picked_image[len(\"image_\"):-len(\".png\")])\n",
    "\n",
    "    img = Image.open(os.path.join(dir, picked_video, picked_image))\n",
    "    data = np.asarray(img, dtype=\"int32\")\n",
    "\n",
    "    mask = np.load(os.path.join(dir, picked_video, \"mask.npy\"))\n",
    "    return data, mask[picked_image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc92fcc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## Plotting images to visualize more masked frames\"\"\"\n",
    "def visualize_labels(dir=dataset_dir + \"/train\", num_frames=5):\n",
    "    all_videos = os.listdir(dir)\n",
    "    picked_video = random.choice(all_videos)\n",
    "    video_path = os.path.join(dir, picked_video)\n",
    "    all_images = sorted([img for img in os.listdir(video_path) if img.startswith('image_')])\n",
    "    picked_images = random.sample(all_images, num_frames)\n",
    "\n",
    "    mask = np.load(os.path.join(video_path, \"mask.npy\"))\n",
    "\n",
    "    plt.figure(figsize=(15, 3 * num_frames))\n",
    "\n",
    "    for i, img_name in enumerate(picked_images):\n",
    "        img_path = os.path.join(video_path, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        print(\"img size: \", img.size, '\\n')\n",
    "        data = np.asarray(img, dtype=\"int32\")\n",
    "        frame_idx = int(img_name[len(\"image_\"):-len(\".png\")])\n",
    "\n",
    "        plt.subplot(num_frames, 2, 2*i + 1)\n",
    "        plt.imshow(data)\n",
    "        plt.title(f\"Frame {frame_idx}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_frames, 2, 2*i + 2)\n",
    "        plt.imshow(mask[frame_idx])\n",
    "        plt.title(f\"Mask for Frame {frame_idx}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed87c0",
   "metadata": {},
   "source": [
    "Call the function to visualize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602ba94a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def visualize(): \n",
    "    print(f\"The training set has {len(os.listdir(dataset_dir + '/train'))} videos, and each video has {len(glob.glob(dataset_dir + '/train/video_00000/*.png'))} frames and {len(glob.glob(dataset_dir + '/train/video_00000/*.npy'))} mask file for all frames\")\n",
    "    print(f\"The validation set has {len(os.listdir(dataset_dir + '/val'))} videos, and each video has {len(glob.glob(dataset_dir + '/val/video_01000/*.png'))} frames and {len(glob.glob(dataset_dir + '/val/video_01000/*.npy'))} mask file for all frames\")\n",
    "    print(f\"The unlabeled set has {len(os.listdir(dataset_dir + '/unlabeled'))} videos, and each video has {len(glob.glob(dataset_dir + '/unlabeled/video_02000/*.png'))} frames and {len(glob.glob(dataset_dir + '/unlabeled/video_02000/*.npy'))} mask file for all frames\")\n",
    "\n",
    "    mask = np.load(dataset_dir + '/train/video_00000/mask.npy')\n",
    "    print(f\"The mask file has the shape {mask.shape}.\")\n",
    "    img = Image.open(dataset_dir + '/train/video_00000/image_0.png')\n",
    "    data = np.asarray(img, dtype=\"int32\")\n",
    "    print(f\"Each image has the shape {data.shape}\")\n",
    "\n",
    "    print(\"Let's visualize them:\")\n",
    "\n",
    "    data, mask = get_a_random_image()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.imshow(data)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the second image\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # visualize_labels(f\"smalldataset/dataset/train\", num_frames=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be53346a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=5, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=16, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc0b57",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    print(device)\n",
    "    visualize()\n",
    "    model = UNet(n_channels=3, n_classes=49, bilinear=True)\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "    model.to(device=device)\n",
    "    train_model(\n",
    "        model=model,\n",
    "        dataset_dir=dataset_dir,\n",
    "        device=device,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.lr,\n",
    "        amp=args.amp\n",
    "    )\n",
    "    test(model, dataset_dir, args.batch_size, device)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
