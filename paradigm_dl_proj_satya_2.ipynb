{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b12be13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0177a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from UNet.unet import UNet\n",
    "from unet_invoke import train_model, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a859915",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "dataset_dir = \"../dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e0bb412",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_a_random_image(dir=dataset_dir + \"/train\"):\n",
    "    all_videos = os.listdir(dir)\n",
    "    picked_video = random.choice(all_videos)\n",
    "    all_images = os.listdir(os.path.join(dir, picked_video))\n",
    "    picked_image = random.choice(all_images)\n",
    "    picked_image_idx = int(picked_image[len(\"image_\"):-len(\".png\")])\n",
    "\n",
    "    img = Image.open(os.path.join(dir, picked_video, picked_image))\n",
    "    data = np.asarray(img, dtype=\"int32\")\n",
    "\n",
    "    mask = np.load(os.path.join(dir, picked_video, \"mask.npy\"))\n",
    "    return data, mask[picked_image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc92fcc1",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"## Plotting images to visualize more masked frames\"\"\"\n",
    "def visualize_labels(dir=dataset_dir + \"/train\", num_frames=5):\n",
    "    all_videos = os.listdir(dir)\n",
    "    picked_video = random.choice(all_videos)\n",
    "    video_path = os.path.join(dir, picked_video)\n",
    "    all_images = sorted([img for img in os.listdir(video_path) if img.startswith('image_')])\n",
    "    picked_images = random.sample(all_images, num_frames)\n",
    "\n",
    "    mask = np.load(os.path.join(video_path, \"mask.npy\"))\n",
    "\n",
    "    plt.figure(figsize=(15, 3 * num_frames))\n",
    "\n",
    "    for i, img_name in enumerate(picked_images):\n",
    "        img_path = os.path.join(video_path, img_name)\n",
    "        img = Image.open(img_path)\n",
    "        print(\"img size: \", img.size, '\\n')\n",
    "        data = np.asarray(img, dtype=\"int32\")\n",
    "        frame_idx = int(img_name[len(\"image_\"):-len(\".png\")])\n",
    "\n",
    "        plt.subplot(num_frames, 2, 2*i + 1)\n",
    "        plt.imshow(data)\n",
    "        plt.title(f\"Frame {frame_idx}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(num_frames, 2, 2*i + 2)\n",
    "        plt.imshow(mask[frame_idx])\n",
    "        plt.title(f\"Mask for Frame {frame_idx}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ed87c0",
   "metadata": {},
   "source": [
    "Call the function to visualize labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602ba94a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def visualize(): \n",
    "    print(f\"The training set has {len(os.listdir(dataset_dir + '/train'))} videos, and each video has {len(glob.glob(dataset_dir + '/train/video_00000/*.png'))} frames and {len(glob.glob(dataset_dir + '/train/video_00000/*.npy'))} mask file for all frames\")\n",
    "    print(f\"The validation set has {len(os.listdir(dataset_dir + '/val'))} videos, and each video has {len(glob.glob(dataset_dir + '/val/video_01000/*.png'))} frames and {len(glob.glob(dataset_dir + '/val/video_01000/*.npy'))} mask file for all frames\")\n",
    "    print(f\"The unlabeled set has {len(os.listdir(dataset_dir + '/unlabeled'))} videos, and each video has {len(glob.glob(dataset_dir + '/unlabeled/video_02000/*.png'))} frames and {len(glob.glob(dataset_dir + '/unlabeled/video_02000/*.npy'))} mask file for all frames\")\n",
    "\n",
    "    mask = np.load(dataset_dir + '/train/video_00000/mask.npy')\n",
    "    print(f\"The mask file has the shape {mask.shape}.\")\n",
    "    img = Image.open(dataset_dir + '/train/video_00000/image_0.png')\n",
    "    data = np.asarray(img, dtype=\"int32\")\n",
    "    print(f\"Each image has the shape {data.shape}\")\n",
    "\n",
    "    print(\"Let's visualize them:\")\n",
    "\n",
    "    data, mask = get_a_random_image()\n",
    "    plt.figure(figsize=(10, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)  # 1 row, 2 columns, 1st subplot\n",
    "    plt.imshow(data)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Plot the second image\n",
    "    plt.subplot(1, 2, 2)  # 1 row, 2 columns, 2nd subplot\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # visualize_labels(f\"smalldataset/dataset/train\", num_frames=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be53346a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='Train the UNet on images and target masks')\n",
    "    parser.add_argument('--epochs', '-e', metavar='E', type=int, default=10, help='Number of epochs')\n",
    "    parser.add_argument('--batch-size', '-b', dest='batch_size', metavar='B', type=int, default=16, help='Batch size')\n",
    "    parser.add_argument('--learning-rate', '-l', metavar='LR', type=float, default=1e-5,\n",
    "                        help='Learning rate', dest='lr')\n",
    "    parser.add_argument('--load', '-f', type=str, default=False, help='Load model from a .pth file')\n",
    "    parser.add_argument('--amp', action='store_true', default=False, help='Use mixed precision')\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fc0b57",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = get_args()\n",
    "    print(device)\n",
    "    visualize()\n",
    "    model = UNet(n_channels=3, n_classes=49, bilinear=True)\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "    model.to(device=device)\n",
    "    train_model(\n",
    "        model=model,\n",
    "        dataset_dir=dataset_dir,\n",
    "        device=device,\n",
    "        epochs=args.epochs,\n",
    "        batch_size=args.batch_size,\n",
    "        learning_rate=args.lr,\n",
    "        amp=args.amp\n",
    "    )\n",
    "    test(model, dataset_dir, args.batch_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1e06171-b72f-4acd-bc0a-2f6d29510b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"segmentation.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "13b4c8ec-7853-472c-b2b4-7a441a29f555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 49, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = UNet(n_channels=3, n_classes=49, bilinear=True)\n",
    "model2 = model.to(memory_format=torch.channels_last)\n",
    "model2.to(device='mps')\n",
    "model2.load_state_dict(torch.load(\"segmentation.pth\"))\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "62ceb07e-656c-477e-afce-254a322a2b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time: 2024-04-25 21:01:22.763174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/whqjy01x0c9d4ml8ffg8n6yw0000gn/T/ipykernel_48375/1083821765.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred_mask = torch.argmax(F.softmax(output), dim=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000_mask.npy\n",
      "2001_mask.npy\n",
      "2002_mask.npy\n",
      "2003_mask.npy\n",
      "2004_mask.npy\n",
      "2005_mask.npy\n",
      "2006_mask.npy\n",
      "2007_mask.npy\n",
      "2008_mask.npy\n",
      "2009_mask.npy\n",
      "2010_mask.npy\n",
      "2011_mask.npy\n",
      "2012_mask.npy\n",
      "2013_mask.npy\n",
      "2014_mask.npy\n",
      "2015_mask.npy\n",
      "2016_mask.npy\n",
      "2017_mask.npy\n",
      "2018_mask.npy\n",
      "2019_mask.npy\n",
      "2020_mask.npy\n",
      "2021_mask.npy\n",
      "2022_mask.npy\n",
      "2023_mask.npy\n",
      "2024_mask.npy\n",
      "2025_mask.npy\n",
      "2026_mask.npy\n",
      "2027_mask.npy\n",
      "2028_mask.npy\n",
      "2029_mask.npy\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart Time:\u001b[39m\u001b[38;5;124m\"\u001b[39m, start_time)\n\u001b[0;32m---> 42\u001b[0m generate_unlabeled_mask(model2, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m22\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "Cell \u001b[0;32mIn[113], line 38\u001b[0m, in \u001b[0;36mgenerate_unlabeled_mask\u001b[0;34m(model, dataset_dir, batch_size, device)\u001b[0m\n\u001b[1;32m     36\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m2000\u001b[39m\u001b[38;5;241m+\u001b[39midx) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_mask.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(file)\n\u001b[0;32m---> 38\u001b[0m np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../unlabeled_masks\u001b[39m\u001b[38;5;124m\"\u001b[39m, file), pred_mask\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from natsort import natsorted\n",
    "import datetime\n",
    "\n",
    "class UnlabeledData():\n",
    "\n",
    "    def __init__(self, videos, transform=None):\n",
    "        self.transforms = transform\n",
    "        self.images, self.masks = [], []\n",
    "        for i in videos:\n",
    "            imgs = os.listdir(i)\n",
    "            imgs = natsorted(imgs)\n",
    "            self.images.extend([i + '/' + img for img in imgs if not img.startswith('mask')])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = np.array(Image.open(self.images[idx]))/255\n",
    "        if self.transforms is not None:\n",
    "            mod = self.transforms(image=img)\n",
    "            img = mod['image']\n",
    "\n",
    "        return img\n",
    "        \n",
    "def generate_unlabeled_mask(model, dataset_dir, batch_size, device):\n",
    "    unlabeled_data_path = os.path.join(dataset_dir,'unlabeled/video_') #Change this to your train set path\n",
    "    unlabeled_data_dir = [unlabeled_data_path + f\"{i:05d}\" for i in range(2000, 2100)]\n",
    "    unlabeled_data = UnlabeledData(unlabeled_data_dir, None)\n",
    "    dataloader = torch.utils.data.DataLoader(unlabeled_data, batch_size=batch_size, shuffle=False)\n",
    "    for idx, (data) in enumerate(dataloader):\n",
    "        images = data.permute(0, 3, 1, 2)\n",
    "        images = images.to(device=device, dtype=torch.float32, memory_format=torch.channels_last)\n",
    "        output = model(images)\n",
    "        pred_mask = torch.argmax(F.softmax(output), dim=1)\n",
    "        file = str(2000+idx) + \"_mask.npy\"\n",
    "        print(file)\n",
    "        np.save(os.path.join(\"../unlabeled_masks\", file), pred_mask.cpu().numpy())\n",
    "\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "print(\"Start Time:\", start_time)\n",
    "generate_unlabeled_mask(model2, \"../dataset\", 22, 'mps')\n",
    "print(\"done\")\n",
    "end_time = datetime.datetime.now()\n",
    "print(\"End Time:\", end_time)\n",
    "time_diff = end_time - start_time\n",
    "print(\"Time Difference:\", time_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6b1e0465-ed51-4927-b6f3-0196fa5ff08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 239.5, 159.5, -0.5)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.load('../unlabeled_masks/2000_mask.npy')\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)  # 1 row, 2 columns, 2nd subplot\n",
    "plt.imshow(data[20])\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6c25a69-3b20-4983-87ec-683b966e8497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5a445c-fcfd-42f6-beab-73a5c2c90dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
